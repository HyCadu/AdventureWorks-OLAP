# üéØ Projeto Pr√°tico: Data Warehouse e ETL com Apache Airflow

Este projeto foi desenvolvido como parte da disciplina de **Engenharia de Dados da UniSales**. O objetivo foi construir um pipeline de dados completo (End-to-End) para migrar dados de um banco transacional (OLTP) para um Data Warehouse (OLAP), utilizando Apache Airflow, Docker e PostgreSQL.

---

## üìã Escopo do Projeto

O projeto utilizou o dataset p√∫blico **AdventureWorks2022** (SQL Server) para simular um cen√°rio real de empresa de varejo.

- **Origem:** SQL Server Express (Rodando no Host Windows)
- **Orquestrador:** Apache Airflow (Rodando em Docker/Linux)
- **Destino:** PostgreSQL (Rodando em Docker)
- **Modelagem:** Esquema Estrela (Star Schema)

---

## üõ†Ô∏è Tecnologias e Arquitetura

| Categoria | Tecnologia |
|-----------|-----------|
| **Linguagem** | Python 3.12 (Pandas, SQLAlchemy) |
| **Infraestrutura** | Docker & Docker Compose |
| **Banco de Dados Origem** | Microsoft SQL Server 2022 Express |
| **Banco de Dados Destino** | PostgreSQL 13 |
| **Bibliotecas Chave** | apache-airflow-providers-microsoft-mssql, pymssql, pandas |

---

## üöß Desafios T√©cnicos e Solu√ß√µes (Troubleshooting)

Durante o desenvolvimento, diversos desafios de infraestrutura e conectividade entre o ambiente Docker (Linux) e o Host (Windows) foram superados. Abaixo, o registro t√©cnico das solu√ß√µes:

### 1. O "Inferno de Depend√™ncias" do Driver MS SQL

**Problema:** A instala√ß√£o do pacote `pymssql` falhava no container Linux devido √† falta de compiladores C++ e bibliotecas de sistema, al√©m de conflitos de vers√£o com o Cython 3.0.

**Solu√ß√£o:** Cria√ß√£o de um Dockerfile personalizado estendendo a imagem oficial do Airflow.
- Instala√ß√£o de depend√™ncias de sistema: `build-essential`, `freetds-dev`, `libssl-dev`
- Atualiza√ß√£o da imagem base para Airflow 2.10.3 para garantir compatibilidade moderna

### 2. Bloqueio de Rede (Erro 20009)

**Problema:** O Airflow n√£o conseguia alcan√ßar o SQL Server (*Adaptive Server is unavailable*), mesmo usando `host.docker.internal`.

**Causa:** O Firewall do Windows bloqueava conex√µes de entrada na porta padr√£o.

**Solu√ß√£o:**
- Cria√ß√£o de Regra de Entrada no Firewall do Windows permitindo tr√°fego TCP na porta 1433
- Configura√ß√£o do SQL Server Configuration Manager para escutar explicitamente no protocolo TCP/IP

### 3. Erro de Protocolo/Criptografia (Erro 20017 - EOF)

**Problema:** A conex√£o era estabelecida (handshake), mas ca√≠a imediatamente com *Unexpected EOF*.

**Causa:** O SQL Server for√ßava criptografia SSL que o driver legado do Linux n√£o conseguia negociar, ou usava portas din√¢micas.

**Solu√ß√£o:**
- Fixa√ß√£o da porta do SQL Server em 1433 (Remo√ß√£o de portas din√¢micas no IPAll)
- Desativa√ß√£o da op√ß√£o "Force Encryption" nas propriedades de rede do SQL Server

### 4. Case Sensitivity no PostgreSQL

**Problema:** Erros de `column does not exist` ao tentar consultar dados carregados pelo Pandas.

**Solu√ß√£o:** Padroniza√ß√£o de nomes de tabelas em min√∫sculas (`fatovendas`) e uso de aspas duplas (`"ValorVenda"`) nas queries SQL para respeitar a sensibilidade a mai√∫sculas/min√∫sculas do PostgreSQL.

---

## ‚öôÔ∏è Configura√ß√£o e Comandos Utilizados

### 1. Prepara√ß√£o do Ambiente (Docker)

O arquivo `docker-compose.yaml` foi configurado para subir os servi√ßos do Airflow e do Postgres.

**Comando para subir a infraestrutura (com build da imagem):**
```bash
docker-compose up -d --build
```

**Comando para acessar o container do Airflow (Manuten√ß√£o):**
```bash
docker exec -it trabalho_etl-airflow-1 bash
```

### 2. Prepara√ß√£o do Banco de Dados (SQL)

Cria√ß√£o das tabelas no Data Warehouse (PostgreSQL):

**Comando para acessar o Postgres:**
```bash
docker exec -it trabalho_etl-postgres_dw-1 psql -U airflow -d data_warehouse
```

**DDL (Exemplo FatoVendas):**
```sql
CREATE TABLE fatovendas (
    id_produto INT,
    DataVenda DATE,
    "ValorVenda" DECIMAL(19, 4),
    "Quantidade" INT,
    "Margem" DECIMAL(19, 4)
    -- ... outros campos
);
```

---

## üöÄ O Processo ETL (DAGs)

Foram desenvolvidas duas DAGs principais em Python:

### 1. `etl_dimensao_produto.py`

- **Extra√ß√£o:** Busca dados de `Production.Product` e `Production.ProductSubcategory`
- **Transforma√ß√£o:** Join para obter nomes de categorias e filtro de produtos acabados
- **Carga:** Salva na tabela `dim_produto` no Postgres (modo replace)

### 2. `etl_fato_vendas.py`

- **Extra√ß√£o:** Busca dados massivos de `Sales.SalesOrderDetail` e `Sales.SalesOrderHeader`
- **Transforma√ß√£o (Pandas):** C√°lculo de m√©tricas de neg√≥cio durante o voo:
  - `Margem = LineTotal - (OrderQty * StandardCost)`
  - `ValorDesconto`
- **Carga:** Salva na tabela `fatovendas` (modo replace)

---

## üìä Resultados e KPIs

O processo foi conclu√≠do com sucesso, carregando **295 produtos** e **121.317 registros de vendas**. Os seguintes indicadores foram validados via SQL no Data Warehouse:

‚úÖ Receita Total  
‚úÖ Quantidade Total Vendida  
‚úÖ Ticket M√©dio  
‚úÖ Margem Bruta M√©dia  
‚úÖ Taxa de Desconto  
‚úÖ Vendas por Categoria  
‚úÖ Margem por Categoria  
‚úÖ Top 5 Produtos (Receita)  
‚úÖ Custo Total vs Receita  
‚úÖ Top Produtos por Desconto  

---

**Desenvolvido por:** Carlos | **Institui√ß√£o:** UniSales | **Ano:** 2025